{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2348af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2table.document import Image\n",
    "import io\n",
    "from PIL import Image as PIL_Image, ImageDraw\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70a67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image, model):\n",
    "    \"\"\"\n",
    "    Classify the image to numbers from 0 to 8, 8 is None\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    image: ndarray of a single channel image.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    pred: classified value corresponding to input image\n",
    "    \n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    resized = cv2.resize(gray, (40, 40))  # 40x40 pixels is the input shape of model\n",
    "\n",
    "    # Expand the dimensions of the image to match the input shape of the model\n",
    "    im = np.expand_dims(resized, axis=0)\n",
    "\n",
    "    result = model.predict(im)\n",
    "    pred = np.argmax(result[0])\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc8bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_extraction_classification_df_return(orddict, img, model):\n",
    "    \"\"\"\n",
    "    Extracts cells of the image from the bbox values in orddict,\n",
    "    classify the image using our custom ocr model, and returns the result as a dataframe\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    orddict: ordered Dictionary having 4 values of bbox\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    df: dataframe of classified values\n",
    "    \n",
    "    \"\"\"\n",
    "    del orddict[0], orddict[4]  # del the first and last keys (rows) of orddict\n",
    "    pred = []\n",
    "    for key, cell_list in orddict.items():  # do the bbox extrn and classification using our model\n",
    "        for cell in cell_list:\n",
    "            x1 = cell.bbox.x1\n",
    "            y1 = cell.bbox.y1\n",
    "            x2 = cell.bbox.x2\n",
    "            y2 = cell.bbox.y2\n",
    "\n",
    "            new_im = img.crop((x1, y1, x2, y2))\n",
    "            im_arr = np.array(new_im)  # Converting new_im (PIL.Image.Image) to numpy array for predict_image()\n",
    "            pred.append(classify_image(im_arr, model))\n",
    "    pred = [0 if num == 8 else num for num in pred]\n",
    "    pred_arr = np.array(pred)\n",
    "    reshaped_pred_arr = pred_arr.reshape(3, 13)  # 3 rows and 13 columns\n",
    "    df = pd.DataFrame(reshaped_pred_arr)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b57f7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_postprocessing(paper_df):\n",
    "    \"\"\"\n",
    "    Preprocessing the dataframe - removing first column,\n",
    "    flattening the np.array of df column-wise,\n",
    "    and returns the values to be added to main mark-dictionary\n",
    "        \n",
    "    Parameter\n",
    "    ---------\n",
    "    paper_df: Output of cell_extraction_classification_df_return(), df with the unwanted first column\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    cell_vals: Values to be added to main mark-dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    paper_df = paper_df.iloc[:, 1:]  # iloc[row, column], removing first column\n",
    "\n",
    "    # Flattening & adding marks to my_dict\n",
    "    paper_arr = paper_df.to_numpy()\n",
    "    flat = paper_arr.flatten(order='F')  # F - flattening column-wise\n",
    "    cell_vals = [i for i in flat]\n",
    "\n",
    "    return cell_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f823ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dictonary(imgs, model):\n",
    "    # Dictionary for storing marks of each papers\n",
    "    my_dict = {'1a': [], '1b': [], '1c': [], '2a': [], '2b': [], '2c': [], '3a': [], '3b': [], '3c': [], '4a': [],\n",
    "               '4b': [], '4c': [], '5a': [], '5b': [], '5c': [], '6a': [], '6b': [], '6c': [], '7a': [], '7b': [],\n",
    "               '7c': [], '8a': [], '8b': [], '8c': [], '9a': [], '9b': [], '9c': [], '10a': [], '10b': [], '10c': [],\n",
    "               '11a': [], '11b': [], '11c': [], '12a': [], '12b': [], '12c': []}\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        img = imgs[i]\n",
    "        dpi = (200, 200)\n",
    "        img.info[\"dpi\"] = dpi\n",
    "        img_bytes = io.BytesIO()\n",
    "        img.save(img_bytes, format='JPEG')\n",
    "        img_bytes.seek(0)\n",
    "        doc = Image(img_bytes)\n",
    "        extracted_tables = doc.extract_tables(implicit_rows=False, min_confidence=50)\n",
    "        orddict = extracted_tables[0].content\n",
    "        img = PIL_Image.open(img_bytes)\n",
    "        if len(orddict.keys()) == 5 and sum(len(value) for value in orddict.values()) == 65:\n",
    "            # if the table recognition is correct, the no of rows will be 5\n",
    "            paper_df = cell_extraction_classification_df_return(orddict, img, model)\n",
    "            marks_for_main_dict = dataframe_postprocessing(paper_df)\n",
    "\n",
    "            for key, value in zip(my_dict.keys(), marks_for_main_dict):\n",
    "                my_dict[key].append(value)  # Adding values to dictionary\n",
    "\n",
    "        else:  # if the table recognition is incorrect\n",
    "            for key in my_dict.keys():\n",
    "                my_dict[key].append(0)  # Adding values to dictionary\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b085195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb628215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"MP_Latest_Model.h5\")\n",
    "image_list = []\n",
    "dict_ret_df_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43f15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
